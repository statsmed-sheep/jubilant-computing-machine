---
title: "Data Appendix"
output: pdf_document
---

```{r, include = FALSE, warning = FALSE, message = FALSE, options(tinytex.verbose = TRUE)}
library(tidyverse)
library(stats)
library(knitr)
library(xtable)

data <- read.csv("data.csv")
# Defining logit function (got an error before)
logit <- qlogis
options(xtable.comment = FALSE)
options(tinytex.verbose = TRUE)
```

# Checking Regression Assumptions

## Linearity

The empirical logit plot seems approximately linear.

```{r, echo = FALSE, warning = FALSE, message = FALSE, out.width = "60%"}
# Code from 18-simplelogistic-lab activity to generate x and y values for plot to check for linearity
data_bin <- data %>%
  # Break HRSLEEP into 10 bins
  mutate(HRSLEEP_group = cut(HRSLEEP, breaks=10)) %>% 
  group_by(HRSLEEP_group) %>%
  # calculate mean HRSLEEP value and proportion obese in each bin
  mutate(binned.y = mean(chronic), binned.x = mean(HRSLEEP)) %>% 
  # transform binned.y from proportion to log(odds)
  mutate(binned.y_logit = logit(binned.y))

# Create plot of log(odds) versus age
ggplot(data_bin, aes(x = binned.x, y = binned.y_logit)) +
  geom_point() + 
  geom_smooth(method = lm, se = FALSE)
```

## Randomness

Obviously, individuals are not assigned BMIs by a spinner model, but since we have a random sample, the randomness assumption is met.

## Independence

As established above for the linear regression model, the independence assumption is reasonable for this data set.

\newpage

# Checking Collinearity between Explanatory Variables

```{r, echo = FALSE, warning = FALSE, messsage = FALSE, results = 'asis'}
data <- data %>% 
  select(chronic, depfreq_often, depfreq_monthly, HRSLEEP, AGE, BMI, activity_score, SEX,
         race_asian, race_black, race_na, income_high, income_middle)
data.cor = cor(data)
round_data <- function(x, digits) {
    # round all numeric variables
    # x: data frame 
    # digits: number of digits to round
    numeric_columns <- sapply(x, mode) == 'numeric'
    x[numeric_columns] <-  round(x[numeric_columns], digits)
    x
}
df_round <- data.frame(round_data(data.cor, 3))
df_round1 <- df_round[, c("chronic", "depfreq_often", "depfreq_monthly", "HRSLEEP", "AGE", "BMI", "activity_score")]
df_round2 <- df_round[, c("SEX", "race_asian", "race_black", "race_na", "income_high", "income_middle")]
df_table1 <- xtable(df_round1)
df_table2 <- xtable(df_round2)
print.xtable(df_table1)
print.xtable(df_table2)
```

The largest magnitude correlation in the correlation matrix above is 0.50. Collinearity therefore appears to not be a concern.

\newpage

# Summary Statistics (Post-data wrangling)

```{r, echo = FALSE, results = 'asis'}
variable <- c("HRSLEEP", "BMI", "AGE", "activity_score")
min <- c("1", "14.98", "18", "17")
max <- c("22", "85.78", "85 (top coded)", "1615")
median <- c(7, 27.11, 51, 896)
mean <- c(7.069339, 28.17239, 50.85831, 862.1115)
std_dev <- c(1.421356, 6.379732, 18.18446, 593.6359)

df_numeric <- data.frame(variable, min, max, median, mean, std_dev)
df_numeric <- xtable(df_numeric)
print.xtable(df_numeric)
```

```{r, echo = FALSE, results = 'asis'}
variable <- c("chronic", "depfreq_often", "depfreq_monthly", "SEX", "income_high", "income_middle", "race_black", "race_asian", "race_na")
yes <- c("407 (1.9%)", "2167 (10.21%)", "1376 (6.48%)", "(female) 11369 (53.6%)", "8181 (38.54%)", "6073 (28.61%)", "2542 (11.97%)", "1169 (5.51%)", "303 (1.43%)")
no <- c("20822 (98.1%)", "19062 (89.79%) ", "19853 (93.52%)", "(male) 9860 (46.4%)", "13048 (61.46%)", "15156 (71.39%)", "18687 (88.03%)", "20060 (94.49%)", "20926 (98.57%)")

df_categorical <- data.frame(variable, yes, no)
df_categorical <- xtable(df_categorical)
print.xtable(df_categorical)
```

# Full Logistic Model Coefficient Summary

```{r, echo = FALSE, results = 'asis'}
coeff <- c("HRSLEEP", "depfreq_often**", "depfreq_monthly", "I(HRSLEEP * depfreq_often)", "I(HRSLEEP * depfreq_monthly)")
value <- c(1.013591536, 3.724750985, 1.393892231, 0.9447263218, 1.045839592)
LCI <- c(9.400140e-01, 1.538202e+00, 3.350283e-01, 8.367457e-01, 8.600010e-01)
UCI <- c(1.089396e+00, 8.944554e+00, 5.819625e+00, 1.065370e+00, 1.257594e+00)
p_val <- c(0.72002, 0.00341, 0.64860, 0.35585, 0.64349)

df <- data.frame(coeff, value, LCI, UCI, p_val)
df <- xtable(df)
print.xtable(df)
```

** = significant at the 0.01 level

# Likelihood Ratio Test

```{r, echo = FALSE, results = 'asis'}
model <- c("Full", "Control")
degf <- c("15", "1")
log_likelihood <- c("-1635.1", "-2012.5")
chisq <- c("--", "754.74")
p_val <- c("--", "<2.2e-16")

lrdata <- data.frame(model, degf, log_likelihood, chisq, p_val)
lrdata <- xtable(lrdata)
print.xtable(lrdata, floating = FALSE)
```
